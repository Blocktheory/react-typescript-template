{"ast":null,"code":"import { __awaiter, __generator } from \"tslib\";\nimport unfetch from 'unfetch';\nvar fetch = unfetch;\n\nif (typeof window !== 'undefined') {\n  fetch = window.fetch || unfetch;\n}\n\nvar MAX_PAYLOAD_SIZE = 500;\n\nfunction kilobytes(buffer) {\n  var size = encodeURI(JSON.stringify(buffer)).split(/%..|./).length - 1;\n  return size / 1024;\n}\n/**\n * Checks if the payload is over or close to\n * the maximum payload size allowed by tracking\n * API.\n */\n\n\nfunction approachingTrackingAPILimit(buffer) {\n  return kilobytes(buffer) >= MAX_PAYLOAD_SIZE - 50;\n}\n\nfunction chunks(batch) {\n  var result = [];\n  var index = 0;\n  batch.forEach(function (item) {\n    var size = kilobytes(result[index]);\n\n    if (size >= 64) {\n      index++;\n    }\n\n    if (result[index]) {\n      result[index].push(item);\n    } else {\n      result[index] = [item];\n    }\n  });\n  return result;\n}\n\nexport default function batch(apiHost, config) {\n  var _a, _b;\n\n  var buffer = [];\n  var pageUnloaded = false;\n  var limit = (_a = config === null || config === void 0 ? void 0 : config.size) !== null && _a !== void 0 ? _a : 10;\n  var timeout = (_b = config === null || config === void 0 ? void 0 : config.timeout) !== null && _b !== void 0 ? _b : 5000;\n\n  function sendBatch(batch) {\n    var _a;\n\n    if (batch.length === 0) {\n      return;\n    }\n\n    var writeKey = (_a = batch[0]) === null || _a === void 0 ? void 0 : _a.writeKey;\n    return fetch(\"https://\".concat(apiHost, \"/b\"), {\n      keepalive: pageUnloaded,\n      headers: {\n        'Content-Type': 'text/plain'\n      },\n      method: 'post',\n      body: JSON.stringify({\n        batch: batch,\n        writeKey: writeKey\n      })\n    });\n  }\n\n  function flush() {\n    return __awaiter(this, void 0, void 0, function () {\n      var batch_1;\n      return __generator(this, function (_a) {\n        if (buffer.length) {\n          batch_1 = buffer;\n          buffer = [];\n          return [2\n          /*return*/\n          , sendBatch(batch_1)];\n        }\n\n        return [2\n        /*return*/\n        ];\n      });\n    });\n  }\n\n  var schedule;\n\n  function scheduleFlush() {\n    if (schedule) {\n      return;\n    }\n\n    schedule = setTimeout(function () {\n      schedule = undefined;\n      flush().catch(console.error);\n    }, timeout);\n  }\n\n  window.addEventListener('beforeunload', function () {\n    pageUnloaded = true;\n\n    if (buffer.length) {\n      var reqs = chunks(buffer).map(sendBatch);\n      Promise.all(reqs).catch(console.error);\n    }\n  });\n\n  function dispatch(_url, body) {\n    return __awaiter(this, void 0, void 0, function () {\n      var bufferOverflow;\n      return __generator(this, function (_a) {\n        buffer.push(body);\n        bufferOverflow = buffer.length >= limit || approachingTrackingAPILimit(buffer);\n        return [2\n        /*return*/\n        , bufferOverflow || pageUnloaded ? flush() : scheduleFlush()];\n      });\n    });\n  }\n\n  return {\n    dispatch: dispatch\n  };\n}","map":{"version":3,"sources":["/Users/apple/Sites/react-typescript-template/node_modules/@segment/analytics-next/src/plugins/segmentio/batched-dispatcher.ts"],"names":[],"mappings":";AAAA,OAAO,OAAP,MAAoB,SAApB;AAGA,IAAI,KAAK,GAAG,OAAZ;;AACA,IAAI,OAAO,MAAP,KAAkB,WAAtB,EAAmC;AACjC,EAAA,KAAK,GAAG,MAAM,CAAC,KAAP,IAAgB,OAAxB;AACD;;AAOD,IAAM,gBAAgB,GAAG,GAAzB;;AAEA,SAAS,SAAT,CAAmB,MAAnB,EAAkC;AAChC,MAAM,IAAI,GAAG,SAAS,CAAC,IAAI,CAAC,SAAL,CAAe,MAAf,CAAD,CAAT,CAAkC,KAAlC,CAAwC,OAAxC,EAAiD,MAAjD,GAA0D,CAAvE;AACA,SAAO,IAAI,GAAG,IAAd;AACD;AAED;;;;AAIG;;;AACH,SAAS,2BAAT,CAAqC,MAArC,EAAoD;AAClD,SAAO,SAAS,CAAC,MAAD,CAAT,IAAqB,gBAAgB,GAAG,EAA/C;AACD;;AAED,SAAS,MAAT,CAAgB,KAAhB,EAA+B;AAC7B,MAAM,MAAM,GAAe,EAA3B;AACA,MAAI,KAAK,GAAG,CAAZ;AAEA,EAAA,KAAK,CAAC,OAAN,CAAc,UAAC,IAAD,EAAK;AACjB,QAAM,IAAI,GAAG,SAAS,CAAC,MAAM,CAAC,KAAD,CAAP,CAAtB;;AACA,QAAI,IAAI,IAAI,EAAZ,EAAgB;AACd,MAAA,KAAK;AACN;;AAED,QAAI,MAAM,CAAC,KAAD,CAAV,EAAmB;AACjB,MAAA,MAAM,CAAC,KAAD,CAAN,CAAc,IAAd,CAAmB,IAAnB;AACD,KAFD,MAEO;AACL,MAAA,MAAM,CAAC,KAAD,CAAN,GAAgB,CAAC,IAAD,CAAhB;AACD;AACF,GAXD;AAaA,SAAO,MAAP;AACD;;AAED,eAAc,SAAU,KAAV,CAAgB,OAAhB,EAAiC,MAAjC,EAAwD;;;AACpE,MAAI,MAAM,GAAa,EAAvB;AACA,MAAI,YAAY,GAAG,KAAnB;AAEA,MAAM,KAAK,GAAG,CAAA,EAAA,GAAA,MAAM,KAAA,IAAN,IAAA,MAAM,KAAA,KAAA,CAAN,GAAM,KAAA,CAAN,GAAA,MAAM,CAAE,IAAR,MAAY,IAAZ,IAAY,EAAA,KAAA,KAAA,CAAZ,GAAY,EAAZ,GAAgB,EAA9B;AACA,MAAM,OAAO,GAAG,CAAA,EAAA,GAAA,MAAM,KAAA,IAAN,IAAA,MAAM,KAAA,KAAA,CAAN,GAAM,KAAA,CAAN,GAAA,MAAM,CAAE,OAAR,MAAe,IAAf,IAAe,EAAA,KAAA,KAAA,CAAf,GAAe,EAAf,GAAmB,IAAnC;;AAEA,WAAS,SAAT,CAAmB,KAAnB,EAAkC;;;AAChC,QAAI,KAAK,CAAC,MAAN,KAAiB,CAArB,EAAwB;AACtB;AACD;;AAED,QAAM,QAAQ,GAAG,CAAA,EAAA,GAAC,KAAK,CAAC,CAAD,CAAN,MAA0B,IAA1B,IAA0B,EAAA,KAAA,KAAA,CAA1B,GAA0B,KAAA,CAA1B,GAA0B,EAAA,CAAE,QAA7C;AAEA,WAAO,KAAK,CAAC,WAAA,MAAA,CAAW,OAAX,EAAkB,IAAlB,CAAD,EAAyB;AACnC,MAAA,SAAS,EAAE,YADwB;AAEnC,MAAA,OAAO,EAAE;AACP,wBAAgB;AADT,OAF0B;AAKnC,MAAA,MAAM,EAAE,MAL2B;AAMnC,MAAA,IAAI,EAAE,IAAI,CAAC,SAAL,CAAe;AAAE,QAAA,KAAK,EAAA,KAAP;AAAS,QAAA,QAAQ,EAAA;AAAjB,OAAf;AAN6B,KAAzB,CAAZ;AAQD;;AAED,WAAe,KAAf,GAAoB;;;;AAClB,YAAI,MAAM,CAAC,MAAX,EAAmB;AACX,UAAA,OAAA,GAAQ,MAAR;AACN,UAAA,MAAM,GAAG,EAAT;AACA,iBAAA,CAAA;AAAA;AAAA,YAAO,SAAS,CAAC,OAAD,CAAhB,CAAA;AACD;;;;;;;AACF;;AAED,MAAI,QAAJ;;AAEA,WAAS,aAAT,GAAsB;AACpB,QAAI,QAAJ,EAAc;AACZ;AACD;;AAED,IAAA,QAAQ,GAAG,UAAU,CAAC,YAAA;AACpB,MAAA,QAAQ,GAAG,SAAX;AACA,MAAA,KAAK,GAAG,KAAR,CAAc,OAAO,CAAC,KAAtB;AACD,KAHoB,EAGlB,OAHkB,CAArB;AAID;;AAED,EAAA,MAAM,CAAC,gBAAP,CAAwB,cAAxB,EAAwC,YAAA;AACtC,IAAA,YAAY,GAAG,IAAf;;AAEA,QAAI,MAAM,CAAC,MAAX,EAAmB;AACjB,UAAM,IAAI,GAAG,MAAM,CAAC,MAAD,CAAN,CAAe,GAAf,CAAmB,SAAnB,CAAb;AACA,MAAA,OAAO,CAAC,GAAR,CAAY,IAAZ,EAAkB,KAAlB,CAAwB,OAAO,CAAC,KAAhC;AACD;AACF,GAPD;;AASA,WAAe,QAAf,CAAwB,IAAxB,EAAsC,IAAtC,EAAkD;;;;AAChD,QAAA,MAAM,CAAC,IAAP,CAAY,IAAZ;AAEM,QAAA,cAAc,GAClB,MAAM,CAAC,MAAP,IAAiB,KAAjB,IAA0B,2BAA2B,CAAC,MAAD,CADjD;AAGN,eAAA,CAAA;AAAA;AAAA,UAAO,cAAc,IAAI,YAAlB,GAAiC,KAAK,EAAtC,GAA2C,aAAa,EAA/D,CAAA;;;AACD;;AAED,SAAO;AACL,IAAA,QAAQ,EAAA;AADH,GAAP;AAGD","sourcesContent":["import unfetch from 'unfetch'\nimport { SegmentEvent } from '../../core/events'\n\nlet fetch = unfetch\nif (typeof window !== 'undefined') {\n  fetch = window.fetch || unfetch\n}\n\ntype BatchingConfig = {\n  size?: number\n  timeout?: number\n}\n\nconst MAX_PAYLOAD_SIZE = 500\n\nfunction kilobytes(buffer: unknown): number {\n  const size = encodeURI(JSON.stringify(buffer)).split(/%..|./).length - 1\n  return size / 1024\n}\n\n/**\n * Checks if the payload is over or close to\n * the maximum payload size allowed by tracking\n * API.\n */\nfunction approachingTrackingAPILimit(buffer: unknown): boolean {\n  return kilobytes(buffer) >= MAX_PAYLOAD_SIZE - 50\n}\n\nfunction chunks(batch: object[]): Array<object[]> {\n  const result: object[][] = []\n  let index = 0\n\n  batch.forEach((item) => {\n    const size = kilobytes(result[index])\n    if (size >= 64) {\n      index++\n    }\n\n    if (result[index]) {\n      result[index].push(item)\n    } else {\n      result[index] = [item]\n    }\n  })\n\n  return result\n}\n\nexport default function batch(apiHost: string, config?: BatchingConfig) {\n  let buffer: object[] = []\n  let pageUnloaded = false\n\n  const limit = config?.size ?? 10\n  const timeout = config?.timeout ?? 5000\n\n  function sendBatch(batch: object[]) {\n    if (batch.length === 0) {\n      return\n    }\n\n    const writeKey = (batch[0] as SegmentEvent)?.writeKey\n\n    return fetch(`https://${apiHost}/b`, {\n      keepalive: pageUnloaded,\n      headers: {\n        'Content-Type': 'text/plain',\n      },\n      method: 'post',\n      body: JSON.stringify({ batch, writeKey }),\n    })\n  }\n\n  async function flush(): Promise<unknown> {\n    if (buffer.length) {\n      const batch = buffer\n      buffer = []\n      return sendBatch(batch)\n    }\n  }\n\n  let schedule: NodeJS.Timeout | undefined\n\n  function scheduleFlush(): void {\n    if (schedule) {\n      return\n    }\n\n    schedule = setTimeout(() => {\n      schedule = undefined\n      flush().catch(console.error)\n    }, timeout)\n  }\n\n  window.addEventListener('beforeunload', () => {\n    pageUnloaded = true\n\n    if (buffer.length) {\n      const reqs = chunks(buffer).map(sendBatch)\n      Promise.all(reqs).catch(console.error)\n    }\n  })\n\n  async function dispatch(_url: string, body: object): Promise<unknown> {\n    buffer.push(body)\n\n    const bufferOverflow =\n      buffer.length >= limit || approachingTrackingAPILimit(buffer)\n\n    return bufferOverflow || pageUnloaded ? flush() : scheduleFlush()\n  }\n\n  return {\n    dispatch,\n  }\n}\n"]},"metadata":{},"sourceType":"module"}